{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saiteja2503/gen-ai-lab/blob/main/2325_WEEK3_Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3_fXr8pDMUS",
        "outputId": "f48c05e6-6f2f-493b-f15f-0985a5d99a27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1: x = 0.74, f(x) = 29.240000000000002\n",
            "Iteration 2: x = 0.6145552, f(x) = 25.9784352\n",
            "Iteration 3: x = 0.5312610807000426, f(x) = 23.81278809820111\n",
            "Iteration 4: x = 0.4693969671925482, f(x) = 22.204321147006254\n",
            "Iteration 5: x = 0.42054837262425754, f(x) = 20.934257688230694\n",
            "Iteration 6: x = 0.38043975469571134, f(x) = 19.891433622088496\n",
            "Iteration 7: x = 0.34660082495852806, f(x) = 19.01162144892173\n",
            "Iteration 8: x = 0.3174771962595419, f(x) = 18.25440710274809\n",
            "Iteration 9: x = 0.29202874676564666, f(x) = 17.592747415906814\n",
            "Iteration 10: x = 0.2695261335763863, f(x) = 17.00767947298604\n",
            "Value of x at minimum: 0.2695261335763863\n",
            "Minimum value of f(x): 17.00767947298604\n"
          ]
        }
      ],
      "source": [
        "# Define the function f(x) (not used directly in optimization)\n",
        "def f(x):\n",
        "    return 5 * x*4 + 3 * x*2 + 10\n",
        "\n",
        "# Define the derivative f'(x)\n",
        "def df(x):\n",
        "    return 20 * x**3 + 6 * x\n",
        "\n",
        "# Gradient Descent implementation\n",
        "def gradient_descent(start_x, learning_rate, iterations):\n",
        "    x = start_x  # Initialize x\n",
        "    for i in range(iterations):\n",
        "        grad = df(x)  # Compute the gradient\n",
        "        x -= learning_rate * grad  # Update x\n",
        "        # Print progress for demonstration\n",
        "        print(f\"Iteration {i+1}: x = {x}, f(x) = {f(x)}\")\n",
        "    return x\n",
        "\n",
        "# Parameters\n",
        "start_x = 1.0       # Initial guess\n",
        "learning_rate = 0.01\n",
        "iterations = 10\n",
        "\n",
        "# Run Gradient Descent\n",
        "minimum_x = gradient_descent(start_x, learning_rate, iterations)\n",
        "\n",
        "# Print final result\n",
        "print(\"Value of x at minimum:\", minimum_x)\n",
        "print(\"Minimum value of f(x):\", f(minimum_x))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the function g(x, y)\n",
        "def g(x, y):\n",
        "    return 3 * x**2 + 5 * (2.718281828459045 ** (-y)) + 10  # Using approximation for e\n",
        "\n",
        "# Define the partial derivatives of g(x, y)\n",
        "def dg_dx(x, y):\n",
        "    return 6 * x  # Derivative of 3x^2 with respect to x\n",
        "\n",
        "def dg_dy(x, y):\n",
        "    return -5 * (2.718281828459045 ** (-y))  # Derivative of 5e^(-y) with respect to y\n",
        "\n",
        "# Gradient Descent implementation for two variables (x, y)\n",
        "def gradient_descent_2d(start_x, start_y, learning_rate, iterations):\n",
        "    x = start_x  # Initialize x\n",
        "    y = start_y  # Initialize y\n",
        "    for i in range(iterations):\n",
        "        grad_x = dg_dx(x, y)  # Compute gradient with respect to x\n",
        "        grad_y = dg_dy(x, y)  # Compute gradient with respect to y\n",
        "\n",
        "        # Update x and y\n",
        "        x -= learning_rate * grad_x\n",
        "        y -= learning_rate * grad_y\n",
        "\n",
        "        # Print progress for demonstration\n",
        "        print(f\"Iteration {i+1}: x = {x}, y = {y}, g(x, y) = {g(x, y)}\")\n",
        "\n",
        "    return x, y\n",
        "\n",
        "# Parameters\n",
        "start_x = 1.0        # Initial guess for x\n",
        "start_y = 1.0        # Initial guess for y\n",
        "learning_rate = 0.01\n",
        "iterations = 10\n",
        "\n",
        "# Run Gradient Descent\n",
        "minimum_x, minimum_y = gradient_descent_2d(start_x, start_y, learning_rate, iterations)\n",
        "\n",
        "# Print final result\n",
        "print(\"Value of x at minimum:\", minimum_x)\n",
        "print(\"Value of y at minimum:\", minimum_y)\n",
        "print(\"Minimum value of g(x, y):\", g(minimum_x, minimum_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jl-GpCT8Dax2",
        "outputId": "37875ee6-c22c-4c43-9c97-6f0691759937"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1: x = 0.94, y = 1.0183939720585722, g(x, y) = 14.456672655087498\n",
            "Iteration 2: x = 0.8835999999999999, y = 1.036452698609447, g(x, y) = 14.115800473484644\n",
            "Iteration 3: x = 0.830584, y = 1.0541882345442934, g(x, y) = 13.811985306391312\n",
            "Iteration 4: x = 0.7807489599999999, y = 1.0716119941765265, g(x, y) = 13.540986991147753\n",
            "Iteration 5: x = 0.7339040224, y = 1.0887347959317717, g(x, y) = 13.299056069253297\n",
            "Iteration 6: x = 0.6898697810559999, y = 1.1055669032014577, g(x, y) = 13.082876799165636\n",
            "Iteration 7: x = 0.64847759419264, y = 1.1221180617486863, g(x, y) = 12.889516796660056\n",
            "Iteration 8: x = 0.6095689385410815, y = 1.1383975340101906, g(x, y) = 12.716382531363704\n",
            "Iteration 9: x = 0.5729948022286167, y = 1.1544141305988047, g(x, y) = 12.561179997918545\n",
            "Iteration 10: x = 0.5386151140948996, y = 1.1701762392765598, g(x, y) = 12.421879959594623\n",
            "Value of x at minimum: 0.5386151140948996\n",
            "Value of y at minimum: 1.1701762392765598\n",
            "Minimum value of g(x, y): 12.421879959594623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the sigmoid function z(x)\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + 2.718281828459045 ** (-x))  # Approximation for e\n",
        "\n",
        "# Define the derivative of sigmoid function z'(x)\n",
        "def sigmoid_derivative(x):\n",
        "    sig = sigmoid(x)\n",
        "    return sig * (1 - sig)  # Derivative of sigmoid function\n",
        "\n",
        "# Gradient Descent implementation\n",
        "def gradient_descent_sigmoid(start_x, learning_rate, iterations):\n",
        "    x = start_x  # Initialize x\n",
        "    for i in range(iterations):\n",
        "        grad = sigmoid_derivative(x)  # Compute the gradient of sigmoid\n",
        "        x -= learning_rate * grad  # Update x\n",
        "\n",
        "        # Print progress for demonstration\n",
        "        print(f\"Iteration {i+1}: x = {x}, z(x) = {sigmoid(x)}\")\n",
        "\n",
        "    return x\n",
        "\n",
        "# Parameters\n",
        "start_x = 1.0       # Initial guess for x\n",
        "learning_rate = 0.01\n",
        "iterations = 10\n",
        "\n",
        "# Run Gradient Descent\n",
        "minimum_x = gradient_descent_sigmoid(start_x, learning_rate, iterations)\n",
        "\n",
        "# Print final result\n",
        "print(\"Value of x at minimum:\", minimum_x)\n",
        "print(\"Minimum value of z(x):\", sigmoid(minimum_x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxXNztExD98U",
        "outputId": "2d1f349b-e68d-49b8-fc46-a9c91ced03c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1: x = 0.9980338806675851, z(x) = 0.7306718405408988\n",
            "Iteration 2: x = 0.9960659756477704, z(x) = 0.7302843997742654\n",
            "Iteration 3: x = 0.9940962846955643, z(x) = 0.7298962555970674\n",
            "Iteration 4: x = 0.9921248075789398, z(x) = 0.7295074072811284\n",
            "Iteration 5: x = 0.9901515440789089, z(x) = 0.7291178541031816\n",
            "Iteration 6: x = 0.9881764939895974, z(x) = 0.7287275953449175\n",
            "Iteration 7: x = 0.98619965711832, z(x) = 0.7283366302930325\n",
            "Iteration 8: x = 0.9842210332856558, z(x) = 0.7279449582392779\n",
            "Iteration 9: x = 0.9822406223255229, z(x) = 0.7275525784805077\n",
            "Iteration 10: x = 0.9802584240852542, z(x) = 0.7271594903187287\n",
            "Value of x at minimum: 0.9802584240852542\n",
            "Minimum value of z(x): 0.7271594903187287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Square Error function\n",
        "def square_error(M, C, x_values, y_values):\n",
        "    total_error = 0\n",
        "    n = len(x_values)\n",
        "    for i in range(n):\n",
        "        predicted = M * x_values[i] + C  # Model prediction\n",
        "        total_error += (y_values[i] - predicted) ** 2  # Square error\n",
        "    return total_error\n",
        "\n",
        "# Define the partial derivatives of Square Error with respect to M and C\n",
        "def gradient_M(M, C, x_values, y_values):\n",
        "    grad_M = 0\n",
        "    n = len(x_values)\n",
        "    for i in range(n):\n",
        "        grad_M += -2 * x_values[i] * (y_values[i] - (M * x_values[i] + C))  # Derivative w.r.t M\n",
        "    return grad_M / n\n",
        "\n",
        "def gradient_C(M, C, x_values, y_values):\n",
        "    grad_C = 0\n",
        "    n = len(x_values)\n",
        "    for i in range(n):\n",
        "        grad_C += -2 * (y_values[i] - (M * x_values[i] + C))  # Derivative w.r.t C\n",
        "    return grad_C / n\n",
        "\n",
        "# Gradient Descent implementation for finding optimal M and C\n",
        "def gradient_descent(x_values, y_values, start_M, start_C, learning_rate, iterations):\n",
        "    M = start_M  # Initialize M (slope)\n",
        "    C = start_C  # Initialize C (intercept)\n",
        "\n",
        "    for i in range(iterations):\n",
        "        grad_M = gradient_M(M, C, x_values, y_values)  # Gradient with respect to M\n",
        "        grad_C = gradient_C(M, C, x_values, y_values)  # Gradient with respect to C\n",
        "\n",
        "        # Update M and C based on the gradients\n",
        "        M -= learning_rate * grad_M\n",
        "        C -= learning_rate * grad_C\n",
        "\n",
        "        # Print progress for demonstration\n",
        "        print(f\"Iteration {i+1}: M = {M}, C = {C}, SE = {square_error(M, C, x_values, y_values)}\")\n",
        "\n",
        "    return M, C\n",
        "\n",
        "# Example data (x_values and corresponding y_values for the expected output)\n",
        "x_values = [1, 2, 3, 4, 5]  # Example x-values\n",
        "y_values = [3, 5, 7, 9, 11]  # Corresponding y-values (expected output)\n",
        "\n",
        "# Parameters\n",
        "start_M = 0.0          # Initial guess for M\n",
        "start_C = 0.0          # Initial guess for C\n",
        "learning_rate = 0.01\n",
        "iterations = 100\n",
        "\n",
        "# Run Gradient Descent\n",
        "optimal_M, optimal_C = gradient_descent(x_values, y_values, start_M, start_C, learning_rate, iterations)\n",
        "\n",
        "# Print final result\n",
        "print(\"Optimal value of M:\", optimal_M)\n",
        "print(\"Optimal value of C:\", optimal_C)\n",
        "print(\"Minimum Square Error (SE):\", square_error(optimal_M, optimal_C, x_values, y_values))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2I_TtHjECQ4",
        "outputId": "fac8f161-a393-45ae-c4c4-fcd6572ec932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1: M = 0.5, C = 0.14, SE = 166.14799999999997\n",
            "Iteration 2: M = 0.8815999999999999, C = 0.2472, SE = 96.8865056\n",
            "Iteration 3: M = 1.172816, C = 0.32936, SE = 56.52390572287999\n",
            "Iteration 4: M = 1.39503488, C = 0.39240384, SE = 33.00215378652569\n",
            "Iteration 5: M = 1.564582976, C = 0.4408536704, SE = 19.29441717737032\n",
            "Iteration 6: M = 1.693923501056, C = 0.478161618432, SE = 11.305805704055544\n",
            "Iteration 7: M = 1.79257063371776, C = 0.506962976, SE = 6.6500200682277715\n",
            "Iteration 8: M = 1.8677873157398528, C = 0.5292694784569344, SE = 3.936443157412701\n",
            "Iteration 9: M = 1.9251179375696692, C = 0.5466168499434045, SE = 2.354692144258242\n",
            "Iteration 10: M = 1.9687949803077376, C = 0.5601774366903562, SE = 1.4325160174263876\n",
            "Iteration 11: M = 2.002049438438614, C = 0.5708461891380848, SE = 0.8947102482900333\n",
            "Iteration 12: M = 2.0273477906338337, C = 0.5793062990490063, SE = 0.5808992433521676\n",
            "Iteration 13: M = 2.04657289875145, C = 0.5860793056299962, SE = 0.39762402783421347\n",
            "Iteration 14: M = 2.061162102688331, C = 0.5915633455923093, SE = 0.2904213196510769\n",
            "Iteration 15: M = 2.07221263936136, C = 0.5960623525191632, SE = 0.22755259599583078\n",
            "Iteration 16: M = 2.080562117550711, C = 0.5998083471070983, SE = 0.19052219886462737\n",
            "Iteration 17: M = 2.0868499508631286, C = 0.6029784531119137, SE = 0.1685517563730685\n",
            "Iteration 18: M = 2.0915642544865256, C = 0.6057078869978877, SE = 0.15536014905172046\n",
            "Iteration 19: M = 2.0950776452796167, C = 0.6080998739887384, SE = 0.14728703361555298\n",
            "Iteration 20: M = 2.0976745708787767, C = 0.6102332177921866, SE = 0.14219932551409586\n",
            "Iteration 21: M = 2.099572172217915, C = 0.6121680791836163, SE = 0.1388539510972936\n",
            "Iteration 22: M = 2.1009362095789568, C = 0.613950387266869, SE = 0.13652649112499926\n",
            "Iteration 23: M = 2.1018932202355742, C = 0.6156152069467943, SE = 0.13479477258813938\n",
            "Iteration 24: M = 2.1025397993669404, C = 0.617189309593724, SE = 0.13341275673494604\n",
            "Iteration 25: M = 2.10294968493059, C = 0.6186931354398331, SE = 0.13223704725524354\n",
            "Iteration 26: M = 2.1031791661194705, C = 0.620142291635201, SE = 0.13118406288780537\n",
            "Iteration 27: M = 2.103271212075075, C = 0.6215486958353287, SE = 0.13020507973537995\n",
            "Iteration 28: M = 2.103258623668439, C = 0.6229214491941176, SE = 0.1292716871606903\n",
            "Iteration 29: M = 2.103166439509735, C = 0.624267502790129, SE = 0.12836731220188313\n",
            "Iteration 30: M = 2.103013772650186, C = 0.6255921663637423, SE = 0.12748228042068618\n",
            "Iteration 31: M = 2.1028152126853206, C = 0.6268994966774563, SE = 0.12661093760847658\n",
            "Iteration 32: M = 2.1025818960939024, C = 0.6281925939827879, SE = 0.12574997245831943\n",
            "Iteration 33: M = 2.1023223233142767, C = 0.629473828337498, SE = 0.12489743910052281\n",
            "Iteration 34: M = 2.102042982484886, C = 0.6307450123718914, SE = 0.12405218748400772\n",
            "Iteration 35: M = 2.1017488255958976, C = 0.6320075331753604, SE = 0.12321353143002678\n",
            "Iteration 36: M = 2.1014436319742784, C = 0.6332624529760994, SE = 0.12238105518957904\n",
            "Iteration 37: M = 2.1011302857613714, C = 0.6345105859981207, SE = 0.12155450071391344\n",
            "Iteration 38: M = 2.1008109877339827, C = 0.635752557132476, SE = 0.12073370196064112\n",
            "Iteration 39: M = 2.1004874170045578, C = 0.6369888467257876, SE = 0.11991854660986578\n",
            "Iteration 40: M = 2.100160854460008, C = 0.6382198247709984, SE = 0.11910895375352809\n",
            "Iteration 41: M = 2.0998322769925464, C = 0.6394457770079779, SE = 0.11830486089315553\n",
            "Iteration 42: M = 2.0995024294337075, C = 0.6406669248482656, SE = 0.11750621636207946\n",
            "Iteration 43: M = 2.099171879467396, C = 0.6418834405852778, SE = 0.11671297490879443\n",
            "Iteration 44: M = 2.098841059549452, C = 0.6430954590055284, SE = 0.11592509512244771\n",
            "Iteration 45: M = 2.098510298908241, C = 0.6443030862524507, SE = 0.11514253793186545\n",
            "Iteration 46: M = 2.098179847973281, C = 0.6455064065929073, SE = 0.11436526573016409\n",
            "Iteration 47: M = 2.097849897023585, C = 0.6467054875826522, SE = 0.11359324186394305\n",
            "Iteration 48: M = 2.097520590423437, C = 0.647900384009584, SE = 0.11282643033493453\n",
            "Iteration 49: M = 2.0971920374897057, C = 0.6490911409039861, SE = 0.11206479562546082\n",
            "Iteration 50: M = 2.096864320787731, C = 0.650277795836524, SE = 0.11130830259606629\n",
            "Iteration 51: M = 2.0965375024642388, C = 0.6514603806725296, SE = 0.11055691642518418\n",
            "Iteration 52: M = 2.0962116290817545, C = 0.6526389229112247, SE = 0.10981060257333183\n",
            "Iteration 53: M = 2.095886735309095, C = 0.6538134467080949, SE = 0.10906932676158565\n",
            "Iteration 54: M = 2.0955628467386083, C = 0.6549839736553873, SE = 0.10833305495838741\n",
            "Iteration 55: M = 2.0952399820367913, C = 0.6561505233779631, SE = 0.10760175337121494\n",
            "Iteration 56: M = 2.0949181545860194, C = 0.6573131139881964, SE = 0.10687538844108609\n",
            "Iteration 57: M = 2.094597373737803, C = 0.6584717624332713, SE = 0.10615392683871608\n",
            "Iteration 58: M = 2.0942776457694903, C = 0.6596264847603377, SE = 0.10543733546165258\n",
            "Iteration 59: M = 2.093958974614582, C = 0.6607772963189615, SE = 0.10472558143197269\n",
            "Iteration 60: M = 2.0936413624202364, C = 0.6619242119157074, SE = 0.10401863209432227\n",
            "Iteration 61: M = 2.093324809972842, C = 0.663067245932179, SE = 0.10331645501415136\n",
            "Iteration 62: M = 2.093009317022886, C = 0.6642064124151649, SE = 0.10261901797607102\n",
            "Iteration 63: M = 2.0926948825329412, C = 0.6653417251454884, SE = 0.1019262889822852\n",
            "Iteration 64: M = 2.0923815048669647, C = 0.6664731976906022, SE = 0.10123823625107202\n",
            "Iteration 65: M = 2.0920691819347965, C = 0.6676008434447723, SE = 0.10055482821529513\n",
            "Iteration 66: M = 2.091757911302455, C = 0.6687246756597891, SE = 0.09987603352093313\n",
            "Iteration 67: M = 2.0914476902763277, C = 0.669844707468446, SE = 0.0992018210256361\n",
            "Iteration 68: M = 2.0911385159674287, C = 0.6709609519024975, SE = 0.0985321597972891\n",
            "Iteration 69: M = 2.0908303853404444, C = 0.6720734219064018, SE = 0.09786701911258723\n",
            "Iteration 70: M = 2.0905232952511623, C = 0.6731821303478471, SE = 0.09720636845562766\n",
            "Iteration 71: M = 2.0902172424750356, C = 0.6742870900258204, SE = 0.09655017751650544\n",
            "Iteration 72: M = 2.0899122237289784, C = 0.6753883136768019, SE = 0.09589841618992419\n",
            "Iteration 73: M = 2.089608235687995, C = 0.6764858139795271, SE = 0.09525105457381333\n",
            "Iteration 74: M = 2.0893052749978644, C = 0.6775796035586569, SE = 0.094608062967956\n",
            "Iteration 75: M = 2.0890033382848148, C = 0.6786696949876119, SE = 0.09396941187262785\n",
            "Iteration 76: M = 2.088702422162899, C = 0.6797561007907708, SE = 0.09333507198724082\n",
            "Iteration 77: M = 2.088402523239615, C = 0.6808388334451814, SE = 0.09270501420900057\n",
            "Iteration 78: M = 2.088103638120189, C = 0.6819179053819009, SE = 0.09207920963157208\n",
            "Iteration 79: M = 2.087805763410833, C = 0.6829933289870516, SE = 0.09145762954375183\n",
            "Iteration 80: M = 2.0875088957212267, C = 0.6840651166026606, SE = 0.09084024542815072\n",
            "Iteration 81: M = 2.0872130316663973, C = 0.6851332805273338, SE = 0.09022702895988612\n",
            "Iteration 82: M = 2.08691816786815, C = 0.6861978330168033, SE = 0.08961795200528351\n",
            "Iteration 83: M = 2.0866243009561485, C = 0.6872587862843782, SE = 0.08901298662058252\n",
            "Iteration 84: M = 2.0863314275687332, C = 0.6883161525013217, SE = 0.08841210505065869\n",
            "Iteration 85: M = 2.0860395443535324, C = 0.6893699437971713, SE = 0.08781527972774718\n",
            "Iteration 86: M = 2.0857486479679253, C = 0.690420172260016, SE = 0.08722248327018041\n",
            "Iteration 87: M = 2.085458735079381, C = 0.6914668499367401, SE = 0.08663368848112979\n",
            "Iteration 88: M = 2.0851698023657126, C = 0.6925099888332424, SE = 0.08604886834735805\n",
            "Iteration 89: M = 2.084881846515261, C = 0.6935496009146348, SE = 0.08546799603798232\n",
            "Iteration 90: M = 2.0845948642270256, C = 0.6945856981054265, SE = 0.08489104490323969\n",
            "Iteration 91: M = 2.0843088522107545, C = 0.6956182922896964, SE = 0.08431798847326785\n",
            "Iteration 92: M = 2.0840238071870067, C = 0.6966473953112572, SE = 0.08374880045688843\n",
            "Iteration 93: M = 2.08373972588719, C = 0.6976730189738116, SE = 0.0831834547403993\n",
            "Iteration 94: M = 2.0834566050535797, C = 0.698695175041104, SE = 0.08262192538638369\n",
            "Iteration 95: M = 2.083174441439326, C = 0.6997138752370672, SE = 0.08206418663251033\n",
            "Iteration 96: M = 2.08289323180845, C = 0.7007291312459663, SE = 0.08151021289035901\n",
            "Iteration 97: M = 2.082612972935833, C = 0.7017409547125399, SE = 0.08095997874424278\n",
            "Iteration 98: M = 2.0823336616071972, C = 0.7027493572421392, SE = 0.08041345895004504\n",
            "Iteration 99: M = 2.0820552946190856, C = 0.7037543504008645, SE = 0.07987062843405626\n",
            "Iteration 100: M = 2.081777868778835, C = 0.7047559457157021, SE = 0.0793314622918301\n",
            "Optimal value of M: 2.081777868778835\n",
            "Optimal value of C: 0.7047559457157021\n",
            "Minimum Square Error (SE): 0.0793314622918301\n"
          ]
        }
      ]
    }
  ]
}